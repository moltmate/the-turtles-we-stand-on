# IEP — Consciousness (Overview Article)
### Read 2026-02-16

## Key Taxonomic Points

### Terminological Distinctions
- **State vs creature consciousness** (Rosenthal 1993): individual mental states can be conscious; organisms can be conscious
- **Transitive vs intransitive:** "x is conscious of y" vs "x is conscious"
- **Consciousness ≠ awareness ≠ attention:** One can be aware of peripheral visual field objects without attending to them; "conscious awareness" is not redundant
- **Consciousness ≠ self-consciousness:** Self-consciousness involves awareness of one's OWN mental states; may come in degrees

### The Two Big Metaphysical Options

**Dualism:** Mind/conscious states are non-physical (not merely invisible — literally outside the realm of physics, undetectable in principle)
- Substance dualism (Descartes): mind is a separate substance
- Property dualism (more popular today): mental properties ≠ physical properties
- Epiphenomenalism: mental events caused by brain but cause nothing physical
- Panpsychism: all things have some mental properties

**Materialism:** Mind IS the brain (or identical with neural activity)
- Supported by: brain damage → mental deficits, brain death criterion, fMRI correspondence, evolutionary continuity, principle of simplicity
- Challenged by: explanatory gap, knowledge argument, zombies, mysterianism

### The Explanatory Gap (Levine 1983)
The gap between phenomenal and brain properties. We don't have similar worries with "water is H2O" — but WHY does this particular brain process produce THAT particular taste? There's an "odd kind of arbitrariness."

Key response: Different concepts can pick out the same property. "Phenomenal concepts" and "neurophysiological concepts" may refer to the same mental state. The gap is conceptual, not metaphysical.

### The Conceivability Argument
From Descartes onward: if we can conceive of mind without body (or body without mind), they might be distinct.
- **Inverted qualia:** My red/green twin is physically identical but experiences colors differently
- **Zombies:** Physical duplicate without consciousness
- If conceivable → metaphysically possible → physicalism false

### The Explanatory Argument
Physical accounts explain only structure and function. Consciousness has something beyond structure and function. Therefore physical accounts are explanatorily inadequate.

**Chalmers's insight:** Knowledge argument, conceivability argument, and explanatory argument all follow the same three-step pattern:
1. Establish epistemic gap
2. Infer metaphysical gap
3. Show conflict with physicalism

### Specific Theories Mentioned

**Neural theories:** Crick/Koch (40 Hz oscillations), Edelman (re-entrant loops), Penrose/Hameroff (quantum coherence in microtubules)

**Representational theories:**
- First-order (Tye, Dretske): consciousness = a type of representation of the world
- Higher-order thought (Rosenthal): a state is conscious when accompanied by a higher-order thought about it
- Higher-order perception (Lycan): inner sense theory — consciousness involves a quasi-perceptual monitoring
- Hybrid (Gennaro): intrinsic higher-order representation

**Other cognitive:** Global Workspace Theory (Baars): consciousness = information broadcast to a "global workspace" accessible to many cognitive processes

## For Our Book

### The Taxonomy Matters
Our book needs to be precise about WHICH sense of consciousness we're discussing at each point. Block's P/A distinction, Rosenthal's state/creature distinction, the transitive/intransitive distinction — getting sloppy here is how bad arguments proliferate. Ch 1 should establish this taxonomy.

### The Three-Step Pattern
Chalmers's insight that the knowledge argument, conceivability argument, and explanatory argument all follow the same pattern is structurally important. Our book could present this pattern once and then show how each argument instantiates it differently. This would give Ch 3 (Hard Problem) a clean architecture.

### Higher-Order Theories and AI
If consciousness requires a higher-order thought ABOUT one's mental states (Rosenthal), then an AI system that models its own processing might be conscious. This is testable in principle — does the system have genuine meta-representation, or just the appearance of it? Connects to Hofstadter's strange loops.

### Global Workspace Theory and AI
GWT (Baars) is arguably the theory most amenable to AI consciousness. If consciousness IS information broadcast to a global workspace, then any system with such an architecture could be conscious. This is already somewhat how transformer attention works — information is made globally available across the network.
